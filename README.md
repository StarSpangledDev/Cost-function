# Cost-function
Compute Cost
Gradient descent involves repeated steps to adjust the value of your parameter  (w,b)  to gradually get a smaller and smaller cost  J(w,b).

At each step of gradient descent, it will be helpful for you to monitor your progress by computing the cost  J(w,b) as  (w,b) gets updated.
In this section, you will implement a function to calculate  J(w,b) so that you can check the progress of your gradient descent implementation.
